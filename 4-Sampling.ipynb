{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQFK5v-u9Eil"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import pie, axis, show\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# global variables (change these per customer)\n",
        "SAMPLE_SIZE = 40\n",
        "LARGE_SAMPLE_SIZE = 20\n",
        "FILE = 'file_name.csv'\n",
        "DATE = 'MM.DD.YY'\n",
        "IVA = 'CustomerName'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WCwdGCg9fPr"
      },
      "outputs": [],
      "source": [
        "# import data\n",
        "data = pd.read_csv(FILE)\n",
        "\n",
        "# peek data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51VpwaJ99k84"
      },
      "outputs": [],
      "source": [
        "# standardize data\n",
        "# ------------------------------------------------------------------------\n",
        "\n",
        "# rename columns\n",
        "data = data.rename(columns={\"Intent\": \"intent\", \"Clean\": \"utterance\"})\n",
        "\n",
        "# select only columns of interest\n",
        "df = data[['intent', 'utterance']]\n",
        "\n",
        "# peek data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwBzY4rTb5Ug"
      },
      "outputs": [],
      "source": [
        "# drop redundant data\n",
        "# ---------------------------------------------------------------------\n",
        "\n",
        "# view intents with most utterances\n",
        "duplicates = df.groupby(df.columns.tolist(), as_index = False).size()\n",
        "duplicates = duplicates.sort_values(by = ['size'], ascending = False)\n",
        "\n",
        "# peek data\n",
        "duplicates.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJGEo51vb5Ug"
      },
      "outputs": [],
      "source": [
        "# drop redundant data\n",
        "# ------------------------------------------------------------------------------------------------\n",
        "\n",
        "# row count before\n",
        "before = df.shape[0]\n",
        "\n",
        "print(\"# of rows before dropping redundant data: \", before)\n",
        "\n",
        "# remove any utterance containing one of the top repeated phrases\n",
        "for i in range(5):\n",
        "    df = df[(df[\"utterance\"].str.contains(duplicates['utterance'].iloc[i]) == False)]\n",
        "    temp = {'intent': duplicates['intent'].iloc[i], 'utterance': duplicates['utterance'].iloc[i]}\n",
        "    df = pd.concat([df, pd.DataFrame([temp])], ignore_index=True)\n",
        "\n",
        "# row count after\n",
        "after = df.shape[0]\n",
        "\n",
        "print(\"# of rows after dropping redundant data: \", after)\n",
        "\n",
        "# difference\n",
        "diff = before - after\n",
        "\n",
        "print(\"# of redundant rows dropped: \", diff)\n",
        "\n",
        "# peek data_unique\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELRYNtABb5Ug"
      },
      "outputs": [],
      "source": [
        "# drop duplicate data\n",
        "# ------------------------------------------------------\n",
        "\n",
        "# row count before\n",
        "before = df.shape[0]\n",
        "print(\"# of rows before dropping duplicates: \", before)\n",
        "\n",
        "# drop duplicates\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# row count after\n",
        "after = df.shape[0]\n",
        "print(\"# of rows after dropping duplicates: \", after)\n",
        "\n",
        "# difference\n",
        "diff = before - after\n",
        "print(\"Total # of duplicates: \", diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miT3RujIb5Uh"
      },
      "outputs": [],
      "source": [
        "# create sample\n",
        "# --------------------------------------------------------------------\n",
        "\n",
        "# create series of intents with their counts\n",
        "data_intents = df.groupby(['intent'])['intent'].count().sort_values()\n",
        "\n",
        "# retreive intents with counts <= SAMPLE_SIZE\n",
        "small_intents = data_intents[data_intents <= SAMPLE_SIZE]\n",
        "\n",
        "# peek small_intents\n",
        "small_intents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_BLSKqrb5Uh"
      },
      "outputs": [],
      "source": [
        "# create sample\n",
        "# ----------------------------\n",
        "\n",
        "# initialize sample dataframe\n",
        "sample = df\n",
        "\n",
        "# view\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVFLcZPIb5Uh"
      },
      "outputs": [],
      "source": [
        "# create sample\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "# create temporary value storing column\n",
        "sample['temp'] = False\n",
        "\n",
        "# loop through columns and label intents within small_intents\n",
        "for r in range(len(sample)):\n",
        "\n",
        "    intent_name = sample['intent'].iloc[r]\n",
        "    if (intent_name in small_intents):\n",
        "        sample['temp'].iloc[r] = True\n",
        "\n",
        "# add all true rows to the sample\n",
        "sample = sample[sample['temp'] == True]\n",
        "\n",
        "# remove temporary column\n",
        "sample = sample.drop(columns = 'temp')\n",
        "\n",
        "# view\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rthH0Tytb5Ui",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# create sample\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "# retreive intents with counts > SAMPLE_SIZE\n",
        "large_intents = data_intents[data_intents > SAMPLE_SIZE]\n",
        "\n",
        "# retreive largest intents\n",
        "largest_intents = large_intents.sort_values(ascending = False)\n",
        "\n",
        "# dropping two\n",
        "# -----------------------------------------------------------\n",
        "# largest two\n",
        "largest_intents = largest_intents.head(2)\n",
        "\n",
        "# drop two largest\n",
        "large_intents = large_intents.drop(large_intents.index[-1])\n",
        "large_intents = large_intents.drop(large_intents.index[-1])\n",
        "\n",
        "# dropping one\n",
        "# -----------------------------------------------------------\n",
        "# largest\n",
        "#largest_intents = largest_intents.head(1)\n",
        "\n",
        "# only largest\n",
        "#large_intents = large_intents.drop(large_intents.index[-1])\n",
        "\n",
        "# peek both\n",
        "print('Large Intents: \\n', large_intents)\n",
        "print('\\nLargest Intents: \\n', largest_intents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_7xFkuWb5Ui",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# create sample\n",
        "# ---------------------------------------------------------------------------------------\n",
        "\n",
        "# add large intents to sample\n",
        "for i in range(len(large_intents)):\n",
        "    temp = df.loc[df['intent'] == large_intents.index[i]].sample(n = SAMPLE_SIZE)\n",
        "    sample = pd.concat([sample, temp], ignore_index=True)\n",
        "\n",
        "# add largest intents to sample\n",
        "for i in range(len(largest_intents)):\n",
        "    temp = df.loc[df['intent'] == largest_intents.index[i]].sample(n = LARGE_SAMPLE_SIZE)\n",
        "    sample = pd.concat([sample, temp], ignore_index=True)\n",
        "\n",
        "# peek sample\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Zv96S72b5Ui"
      },
      "outputs": [],
      "source": [
        "# clean sample\n",
        "sample = sample.drop(columns = 'temp')\n",
        "\n",
        "# preview sample\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkBu5d_Tb5Ui"
      },
      "outputs": [],
      "source": [
        "# check sample for all intent representation\n",
        "# ------------------------------------------------------\n",
        "\n",
        "# raw data intent count\n",
        "before = data['intent'].unique().size\n",
        "print(\"# of unique intents in raw data: \", before)\n",
        "\n",
        "# sample intent count\n",
        "after = sample['intent'].unique().size\n",
        "print(\"# of unique intents in sample: \", after)\n",
        "\n",
        "# difference\n",
        "diff = before - after\n",
        "print(\"This should be zero: \", diff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1NqFJNvb5Uj"
      },
      "outputs": [],
      "source": [
        "# seperate sample into train and test\n",
        "sample_train, sample_test = train_test_split(sample, test_size = 0.2, train_size = 0.8)\n",
        "\n",
        "# sort both samples\n",
        "sample_train = sample_train.sort_values(by = 'intent').loc[:, ['utterance', 'intent']]\n",
        "sample_test = sample_test.sort_values(by = 'intent').loc[:, ['utterance', 'intent']]\n",
        "\n",
        "# peek one\n",
        "sample_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prints data point metrics\n",
        "\n",
        "print(f'Train data points: {sample_train.shape[0]}.')\n",
        "print(f'Test data points: {sample_test.shape[0]}.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTeJkY95b5Uj"
      },
      "outputs": [],
      "source": [
        "# assemble filenames\n",
        "train_filename = (IVA + \"_train_sample_\" + DATE + \".csv\")\n",
        "test_filename = (IVA + \"_test_sample_\" + DATE + \".csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZo97RR5b5Uj"
      },
      "outputs": [],
      "source": [
        "throw error to double check before exporting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHtNEFcNb5Uj"
      },
      "outputs": [],
      "source": [
        "# save files\n",
        "sample_train.to_csv(train_filename, index=False)\n",
        "sample_test.to_csv(test_filename, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
